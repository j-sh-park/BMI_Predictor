---
title: "project"
author: "Anker,Alice,Utsav,James"
date: "11/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
devtools::install_github("ropenscilabs/gendercodeR")
#import libraries
library(tidyverse)
library(janitor)
library(skimr)
library(gridExtra)
library(GGally)
library(qtlcharts)
library(ggfortify) 
library(sjPlot)
options(knitr.table.format = "html")
```


# Exploratory Data Analysis(EDA)
```{r results ='hide'}
data = read.table("bodyfat.txt",header=TRUE) #read the data

glimpse(data)# Quick glimpse of the data
```
There are 250 observations and 16 variables in this data set. Each row represents an individual response and each column represents the features

```{r results='hide'}
skimr::skim(data)
```
```{r}
#Delete the density feature as the percentage body fat is calculated based on density. There is a strong correlation between each other
data = subset(data, select = -1)
```

## Variable selection using forward AIC

```{r}
M0 = lm(Pct.BF ~ 1, data = data) # Null model
M1 = lm(Pct.BF ~ ., data = data) # FUll model
step.fwd.aic = step(M0, scope = list(lower = M0, upper = M1), direction = "forward", trace = FALSE) 
round(summary(step.fwd.aic)$coef,3)
```

## Variable selection using backward AIC
```{r}
step.back.aic = step(M1, direction = "backward", trace = FALSE) 
round(summary(step.back.aic)$coef,3)
```
### Compare the backward and forward AIC methods

```{r}
sjPlot::tab_model( step.fwd.aic, step.back.aic, show.ci = FALSE, show.aic = TRUE, dv.labels = c("Forward model", "Backward model") )
```

Since backward AIC gives us smaller AIC, we decided to use backward AIC for variable selection


##Fit a simple linear mode



## pcentage body fat vs Height 
```{r}
lm1 = lm(Pct.BF ~ Height , data = data) 
summary(lm1)
sjPlot::tab_model(lm1, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF ~ Height, data = data) 
abline(lm1, lwd = 3, col = "red")
```
```{r}
fitted1 = 477.2 + (-433.9) * data$Height
resid1 = data$Pct.BF - fitted1
```

## percentage body fat vs age
```{r}
lm2 = lm(Pct.BF ~ Age, data = data) 
summary(lm2)
sjPlot::tab_model(lm2, show.ci = FALSE)
```
```{r}
par(cex = 2) 
plot(Pct.BF~Age, data = data) 
abline(lm2, lwd = 3, col = "red")
```
```{r}
fitted2 = 10.35029  +  0.19342 * data$Age
resid2 = data$Pct.BF - fitted2
```

## percentage body fat vs abdomen
```{r}
lm3 = lm(Pct.BF ~ Abdomen, data = data) 
summary(lm3)
sjPlot::tab_model(lm3, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF~Abdomen, data = data) 
abline(lm3, lwd = 3, col = "red")
```
```{r}
fitted3 = -42.73413  + 0.66928 * data$Abdomen
resid3 = data$Pct.BF - fitted3
```

## pcentage body fat vs Neck

```{r}
lm4 = lm(Pct.BF ~ Neck, data = data) 
summary(lm4)
sjPlot::tab_model(lm4, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF~Neck, data = data) 
abline(lm4, lwd = 3, col = "red")
```

```{r}
fitted4 = -48.0929  +  1.7690  * data$Neck
resid4 = data$Pct.BF - fitted4
```

## pcentage body fat vs Hip

```{r}
lm5 = lm(Pct.BF ~ Hip, data = data) 
summary(lm5)
sjPlot::tab_model(lm5, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF~Hip, data = data) 
abline(lm5, lwd = 3, col = "red")
```

```{r}
fitted5 = -62.1198 +  0.8144  * data$Hip
resid5 = data$Pct.BF - fitted5
```

## pcentage body fat vs Thigh

```{r}
lm6 = lm(Pct.BF ~ Thigh, data = data) 
summary(lm6)
sjPlot::tab_model(lm6, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF~Thigh, data = data) 
abline(lm6, lwd = 3, col = "red")
```

```{r}
fitted6 = -62.1198 +  0.8144  * data$Thigh
resid6 = data$Pct.BF - fitted6
```

## pcentage body fat vs Forearm

```{r}
lm7 = lm(Pct.BF ~ Forearm, data = data) 
summary(lm7)
sjPlot::tab_model(lm7, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF~Forearm, data = data) 
abline(lm7, lwd = 3, col = "red")
```

```{r}
fitted7 = -23.7060 + 1.4911 * data$Thigh
resid7 = data$Pct.BF - fitted7
```


## pcentage body fat vs wrist

```{r}
lm8 = lm(Pct.BF ~ Wrist, data = data) 
summary(lm8)
sjPlot::tab_model(lm8, show.ci = FALSE)
```

```{r}
par(cex = 2) 
plot(Pct.BF~Wrist, data = data) 
abline(lm8, lwd = 3, col = "red")
```

```{r}
fitted8 = -37.0207 + 3.0763 * data$Thigh
resid8 = data$Pct.BF - fitted8
```


## Chekcing assumptions

```{r}
ggplot(data, 
              aes(x = Height , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "height",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 
```

###Check linearity
```{r}
#percentage body fat vs density
p1 = ggplot(data, 
              aes(x = Height , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "height",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p2 = ggplot(data, 
              aes(x = Age , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Age",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p3 = ggplot(data, 
              aes(x = Abdomen , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Abdomen",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p4 = ggplot(data, 
              aes(x = Neck , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Neck",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p5 = ggplot(data, 
              aes(x = Hip , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Hip",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p6 = ggplot(data, 
              aes(x = Thigh, y =  Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Thigh",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p7 = ggplot(data, 
              aes(x = Forearm, y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Forearm",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 

p8 = ggplot(data, 
              aes(x = Wrist , y = Pct.BF)) + 
     geom_point(size = 1) + 
     theme_classic(base_size = 12) + 
     labs(x = "Wrist",
          y = "Percentage body fat") +
     geom_smooth(method = "lm", se = FALSE) 


grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8, nrow =4, ncol = 2)
```

All three plots shows strong linearity, though the variance of percentage body fat for people age 60 to 80 is a bit smaller than the people age from 20 -60. The linearity assumption is met.
### Check independence

All the observations are taken from different people, the data are independent of each other

### Check homoskedasiticy

```{r}
p9 = ggplot(data, 
            aes(x = Height, y = resid1)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Height", y = "Residual") + 
     geom_hline(yintercept = 0) 

p10 = ggplot(data, 
            aes(x = Age, y = resid2)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Age", y = "Residual") + 
     geom_hline(yintercept = 0) 

p11 = ggplot(data, 
            aes(x = Abdomen, y = resid3)) + 
      geom_point(size = 1) + theme_classic(base_size = 12) + 
      labs(x = "Abdomen", y = "Residual") + 
      geom_hline(yintercept = 0) 

p12 = ggplot(data, 
            aes(x =Neck, y = resid4)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Neck", y = "Residual") + 
     geom_hline(yintercept = 0) 

p13 = ggplot(data, 
            aes(x = Hip, y = resid5)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Hip", y = "Residual") + 
     geom_hline(yintercept = 0) 

p14 = ggplot(data, 
            aes(x = Thigh, y = resid6)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Thigh", y = "Residual") + 
     geom_hline(yintercept = 0) 

p15 = ggplot(data, 
            aes(x = Forearm, y = resid7)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Forearm", y = "Residual") + 
     geom_hline(yintercept = 0) 

p16 = ggplot(data, 
            aes(x = Wrist, y = resid8)) + 
     geom_point(size = 1) + theme_classic(base_size = 12) + 
     labs(x = "Wrist", y = "Residual") + 
     geom_hline(yintercept = 0) 

grid.arrange(p9, p10, p11,p12,p13,p14,p15,p16 ,nrow =4, ncol = 2)
```
The data in all plots seems have equal variance. A few outliers can be ignored. The homoskedasiticy assumption is met.


### Check normality

```{r}
autoplot(lm1, which = 1:2)
autoplot(lm2, which = 1:2)
autoplot(lm3, which = 1:2)
autoplot(lm4, which = 1:2)
autoplot(lm5, which = 1:2)
autoplot(lm6, which = 1:2)
autoplot(lm7, which = 1:2)
autoplot(lm8, which = 1:2)
```

```{r}
##Check multicolinearity
 
#extract the data which is strongly correlated to percentage body fat
corr = data %>%
  select(Pct.BF, Height, Abdomen, Wrist) #select corr > 0.7 or < -0.7

#correlation matrix
GGally::ggpairs(corr) + theme_bw(base_size = 15)
```
It seems like there is a strong negative correlation between density and abdomen. We should drop one of them

# Modelling

#final linear regression model
```{r}
lm_simple = lm(Pct.BF ~ Height + Abdomen + Wrist, data = data) # 
round(summary(lm_simple)$coef, 3)
sjPlot::tab_model(lm_simple, show.ci = FALSE)
```


```{r}
#full linear regression
lm_full = lm(Pct.BF ~ ., data = data) # all variables
round(summary(lm_full)$coef, 3)
sjPlot::tab_model(lm_full, show.ci = FALSE)
```


```{r}
#10 fold cross validation method to select  
set.seed(2020) 
nrow(data)
fold_id = c(rep(1:10, each = 25))
data$fold_id = sample(fold_id, replace = FALSE)
head(data)
```


```{r}
k = 10 
simple_mse = full_mse = vector(mode = "numeric", length = k) 
simple_mae = full_mae = vector(mode = "numeric", length = k)
```


```{r}
for(i in 1:k) {
  test_set = data[fold_id == i,] 
  training_set = data[fold_id != i,]
  
  simple_lm = lm(Pct.BF ~ Height + Abdomen + Wrist, data = training_set)
  simple_pred = predict(simple_lm, test_set) 
  simple_mse[i] = mean((test_set$Pct.BF - simple_pred)^2) 
  simple_mae[i] = mean(abs(test_set$Pct.BF - simple_pred)) 
  full_lm = lm(Pct.BF ~., data = training_set) 
  full_pred = predict(full_lm, test_set) 
  full_mse[i] = mean((test_set$Pct.BF - full_pred)^2) 
  full_mae[i] = mean(abs(test_set$Pct.BF - full_pred)) }
```
```{r}
cv_res = tibble(simple_mse, full_mse, simple_mae, full_mae) 
cv_res
```

```{r}
#Root mean square errors:
c(sqrt(mean(simple_mse)), 
  sqrt(mean(full_mse))) %>% round(2)
```


```{r}
#Mean absolute errors:
c(mean(simple_mae), 
  mean(full_mae)) %>% round(2)
```
```{r}
result = matrix(c(sqrt(mean(simple_mse)),sqrt(mean(full_mse)),mean(simple_mae),mean(full_mae)), ncol=2)
colnames(result)= c('RMSE', 'MAE')
rownames(result) = c('simple model', 'full model')
#result.table = as.table(result)
knitr::kable(result)
```


```{r}
cv_res %>% gather(key = "metric", value = "error") %>% 
  separate(col = metric, into = c("model","metric")) %>% 
  ggplot(aes(x = model, y = error)) + facet_wrap(~metric, scales = "free_y") + 
  geom_boxplot()
```

## t-test for average dataset height and average height of American male

```{r}
avg_h = 69.1
x = data$Height
n = length(x)
t.test(x, mu = 69.1, alternative = "less")
t0 = (mean(x) - 69.1)/(sd(x)/sqrt(n))
pval = pt(t0, n - 1)
pval
```

